[xlog] 13-01-14 17:00:26 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:26 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:26 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_1910297907 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:27 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:27 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:27 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-1200850464 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:28 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:28 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:28 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_723302351 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:29 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:29 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:29 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-647002863 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:30 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:30 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:30 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-1771486714 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:31 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:31 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:31 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-1265660599 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:32 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:32 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:32 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_563896603 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:33 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:33 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:33 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-1399724120 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:35 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:35 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:35 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_759710149 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:36 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:36 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:36 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_1280932799 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:37 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:37 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:37 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_1551258257 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:38 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:38 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:38 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-190783087 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:39 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:39 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:39 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-83857501 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:40 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:40 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:40 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-2072906069 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:41 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:41 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:41 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-235700451 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:42 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:42 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:42 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_2063090945 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:43 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:43 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:43 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-9751254 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:45 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:45 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:45 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-291036545 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:46 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:46 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:46 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_1156986618 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:47 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:47 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:47 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-16.x1 for DFSClient_-905508171 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:00:48 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:00:48 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:00:48 INFO storage.EventListener: Fail to send request,try sleep 300000ms
[xlog] 13-01-14 17:00:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:01:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:02:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:03:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:04:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:05:48 DEBUG impl.HDFSAdapter: success to get HDFSOutputStream!
[xlog] 13-01-14 17:05:49 DEBUG sync.SyncTimer: it start 1 threads to sync data!
[xlog] 13-01-14 17:06:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:07:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:08:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:08:53 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is Filesystem closed
[xlog] 13-01-14 17:08:54 DEBUG impl.HDFSAdapter: success to get HDFSOutputStream!
[xlog] 13-01-14 17:09:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:10:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:11:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:12:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:13:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:14:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:15:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:16:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:17:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:18:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:19:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:20:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:21:49 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:22:48 DEBUG cache.WriteLocalOnlyCategoriesCache: WRITE LOCAL ONLY CATEGORIES LIST such as :
[xlog] 13-01-14 17:22:48 DEBUG cache.WriteLocalOnlyCategoriesCache: /test/ad
[xlog] 13-01-14 17:22:48 DEBUG cache.WriteLocalOnlyCategoriesCache: /test/feed
[xlog] 13-01-14 17:22:48 DEBUG cache.WriteLocalOnlyCategoriesCache: /som/cdn
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:zookeeper.version=3.3.3-1203054, built on 11/17/2011 05:47 GMT
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:host.name=xianquanzhang
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:java.version=1.6.0_30
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:java.vendor=Sun Microsystems Inc.
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:java.home=/home/xianquanzhang/install/jdk1.6.0_30/jre
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:java.class.path=/home/xianquanzhang/xlog/src/java/dispatcher/target/test-classes:/home/xianquanzhang/xlog/src/java/dispatcher/target/classes:/home/xianquanzhang/.m2/repository/javax/mail/mail/1.4/mail-1.4.jar:/home/xianquanzhang/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/home/xianquanzhang/.m2/repository/javax/jms/jms/1.1/jms-1.1.jar:/home/xianquanzhang/.m2/repository/com/zeroc/Ice/3.3.1/Ice-3.3.1.jar:/home/xianquanzhang/.m2/repository/org/apache/zookeeper/zookeeper/3.3.4/zookeeper-3.3.4.jar:/home/xianquanzhang/.m2/repository/log4j/log4j/1.2.15/log4j-1.2.15.jar:/home/xianquanzhang/.m2/repository/com/sun/jdmk/jmxtools/1.2.1/jmxtools-1.2.1.jar:/home/xianquanzhang/.m2/repository/com/sun/jmx/jmxri/1.2.1/jmxri-1.2.1.jar:/home/xianquanzhang/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/home/xianquanzhang/.m2/repository/junit/junit/4.0/junit-4.0.jar:/home/xianquanzhang/.m2/repository/com/google/protobuf/protobuf-java/2.2.0/protobuf-java-2.2.0.jar:/home/xianquanzhang/.m2/repository/org/apache/hadoop/hadoop-core/1.0.3/hadoop-core-1.0.3.jar:/home/xianquanzhang/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/xianquanzhang/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/home/xianquanzhang/.m2/repository/commons-httpclient/commons-httpclient/3.0.1/commons-httpclient-3.0.1.jar:/home/xianquanzhang/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/home/xianquanzhang/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/home/xianquanzhang/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/home/xianquanzhang/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/home/xianquanzhang/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/home/xianquanzhang/.m2/repository/commons-lang/commons-lang/2.4/commons-lang-2.4.jar:/home/xianquanzhang/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/home/xianquanzhang/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/home/xianquanzhang/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/home/xianquanzhang/.m2/repository/commons-net/commons-net/1.4.1/commons-net-1.4.1.jar:/home/xianquanzhang/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/home/xianquanzhang/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/home/xianquanzhang/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/home/xianquanzhang/.m2/repository/tomcat/jasper-runtime/5.5.12/jasper-runtime-5.5.12.jar:/home/xianquanzhang/.m2/repository/tomcat/jasper-compiler/5.5.12/jasper-compiler-5.5.12.jar:/home/xianquanzhang/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/home/xianquanzhang/.m2/repository/org/mortbay/jetty/servlet-api-2.5/6.1.14/servlet-api-2.5-6.1.14.jar:/home/xianquanzhang/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/home/xianquanzhang/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/home/xianquanzhang/.m2/repository/ant/ant/1.6.5/ant-1.6.5.jar:/home/xianquanzhang/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/home/xianquanzhang/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/home/xianquanzhang/.m2/repository/net/sf/kosmosfs/kfs/0.3/kfs-0.3.jar:/home/xianquanzhang/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/home/xianquanzhang/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.0.1/jackson-mapper-asl-1.0.1.jar:/home/xianquanzhang/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.0.1/jackson-core-asl-1.0.1.jar:/home/xianquanzhang/.m2/repository/org/slf4j/slf4j-api/1.5.8/slf4j-api-1.5.8.jar:/home/xianquanzhang/.m2/repository/org/slf4j/slf4j-log4j12/1.5.8/slf4j-log4j12-1.5.8.jar:/home/xianquanzhang/.m2/repository/com/sso/sso-client/1.0/sso-client-1.0.jar:/home/xianquanzhang/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/home/xianquanzhang/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/home/xianquanzhang/.m2/repository/com/renren/monitor-core/0.0.1-SNAPSHOT/monitor-core-0.0.1-SNAPSHOT.jar:/home/xianquanzhang/.m2/repository/org/apache/httpcomponents/httpclient/4.2.2/httpclient-4.2.2.jar:/home/xianquanzhang/.m2/repository/org/apache/httpcomponents/httpcore/4.2.2/httpcore-4.2.2.jar
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:java.library.path=/home/xianquanzhang/install/jdk1.6.0_30/jre/lib/i386/server:/home/xianquanzhang/install/jdk1.6.0_30/jre/lib/i386:/home/xianquanzhang/install/jdk1.6.0_30/jre/../lib/i386:/home/xianquanzhang/install/jdk1.6.0_30/jre/lib/i386/client:/home/xianquanzhang/install/jdk1.6.0_30/jre/lib/i386::/usr/java/packages/lib/i386:/lib:/usr/lib
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:os.name=Linux
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:os.arch=i386
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:os.version=2.6.32-39-generic
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:user.name=xianquanzhang
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:user.home=/home/xianquanzhang
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Client environment:user.dir=/home/xianquanzhang/xlog/src/java/dispatcher
[xlog] 13-01-14 17:22:48 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=10.2.62.22:2222 sessionTimeout=10000 watcher=dp.election.impl.DefaultWatcher@179a49f
[xlog] 13-01-14 17:22:49 INFO zookeeper.ClientCnxn: Opening socket connection to server /10.2.62.22:2222
[xlog] 13-01-14 17:22:49 INFO zookeeper.ClientCnxn: Socket connection established to xianquanzhang.local/10.2.62.22:2222, initiating session
[xlog] 13-01-14 17:22:49 INFO zookeeper.ClientCnxn: Session establishment complete on server xianquanzhang.local/10.2.62.22:2222, sessionid = 0x13c37ad358e000c, negotiated timeout = 10000
[xlog] 13-01-14 17:22:49 INFO impl.DefaultWatcher: watcher event had happen,the event state is : SyncConnected
[xlog] 13-01-14 17:22:49 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
[xlog] 13-01-14 17:22:49 INFO mortbay.log: jetty-6.1.26
[xlog] 13-01-14 17:22:49 INFO mortbay.log: Started SelectChannelConnector@10.2.62.22:20002
[xlog] 13-01-14 17:23:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:24:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:25:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:26:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:27:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:28:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:29:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:30:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:31:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:32:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:33:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:34:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:35:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:36:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:37:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:38:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:39:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:40:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:41:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:42:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:43:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:44:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:45:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:46:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:47:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:48:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:49:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:50:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:51:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:52:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:53:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:54:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:55:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:56:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:57:14 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-17.x1 for DFSClient_-1584345709 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:57:14 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:57:14 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:57:14 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-17.x1 for DFSClient_1537824049 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:57:15 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:57:15 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:57:15 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-17.x1 for DFSClient_2076703542 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:57:16 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:57:16 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:57:16 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-17.x1 for DFSClient_-458300576 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:57:16 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 17:57:16 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 17:57:16 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.protocol.AlreadyBeingCreatedException: failed to create file /user/xianquanzhang/3g/game/test0/2013-01-14-17.x1 for DFSClient_438668050 on client 10.2.62.22, because this file is already being created by NN_Recovery on 10.2.62.22
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.recoverLeaseInternal(FSNamesystem.java:1406)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1246)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:1426)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.append(NameNode.java:643)
	at sun.reflect.GeneratedMethodAccessor8.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 17:57:17 DEBUG impl.HDFSAdapter: success to get HDFSOutputStream!
[xlog] 13-01-14 17:57:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:58:48 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 17:58:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:58:49 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 17:58:50 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 17:58:51 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 17:58:52 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 4 time(s).
[xlog] 13-01-14 17:58:53 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 5 time(s).
[xlog] 13-01-14 17:58:54 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 6 time(s).
[xlog] 13-01-14 17:58:55 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 7 time(s).
[xlog] 13-01-14 17:58:56 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 8 time(s).
[xlog] 13-01-14 17:58:57 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 9 time(s).
[xlog] 13-01-14 17:58:57 WARN hdfs.DFSClient: Problem renewing lease for DFSClient_-895313119
java.net.ConnectException: Call to xianquanzhang.local/10.2.62.22:8020 failed on connection exception: java.net.ConnectException: 拒绝连接
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy1.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy1.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1359)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1371)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 12 more
[xlog] 13-01-14 17:58:59 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 17:59:00 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 17:59:01 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 17:59:02 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 17:59:03 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 4 time(s).
[xlog] 13-01-14 17:59:04 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 5 time(s).
[xlog] 13-01-14 17:59:05 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 6 time(s).
[xlog] 13-01-14 17:59:06 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 7 time(s).
[xlog] 13-01-14 17:59:07 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 8 time(s).
[xlog] 13-01-14 17:59:08 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 9 time(s).
[xlog] 13-01-14 17:59:08 WARN hdfs.DFSClient: Problem renewing lease for DFSClient_-895313119
java.net.ConnectException: Call to xianquanzhang.local/10.2.62.22:8020 failed on connection exception: java.net.ConnectException: 拒绝连接
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy1.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy1.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1359)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1371)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 12 more
[xlog] 13-01-14 17:59:10 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 17:59:11 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 17:59:12 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 17:59:13 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 17:59:14 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 4 time(s).
[xlog] 13-01-14 17:59:15 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 5 time(s).
[xlog] 13-01-14 17:59:16 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 6 time(s).
[xlog] 13-01-14 17:59:17 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 7 time(s).
[xlog] 13-01-14 17:59:18 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 8 time(s).
[xlog] 13-01-14 17:59:19 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 9 time(s).
[xlog] 13-01-14 17:59:19 WARN hdfs.DFSClient: Problem renewing lease for DFSClient_-895313119
java.net.ConnectException: Call to xianquanzhang.local/10.2.62.22:8020 failed on connection exception: java.net.ConnectException: 拒绝连接
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy1.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy1.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1359)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1371)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 12 more
[xlog] 13-01-14 17:59:21 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 17:59:22 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 17:59:23 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 17:59:24 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 17:59:25 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 4 time(s).
[xlog] 13-01-14 17:59:26 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 5 time(s).
[xlog] 13-01-14 17:59:27 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 6 time(s).
[xlog] 13-01-14 17:59:28 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 7 time(s).
[xlog] 13-01-14 17:59:29 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 8 time(s).
[xlog] 13-01-14 17:59:30 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 9 time(s).
[xlog] 13-01-14 17:59:30 WARN hdfs.DFSClient: Problem renewing lease for DFSClient_-895313119
java.net.ConnectException: Call to xianquanzhang.local/10.2.62.22:8020 failed on connection exception: java.net.ConnectException: 拒绝连接
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy1.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy1.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1359)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1371)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 12 more
[xlog] 13-01-14 17:59:32 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 17:59:33 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 17:59:34 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 17:59:35 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 17:59:36 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 4 time(s).
[xlog] 13-01-14 17:59:37 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 5 time(s).
[xlog] 13-01-14 17:59:38 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 6 time(s).
[xlog] 13-01-14 17:59:39 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 7 time(s).
[xlog] 13-01-14 17:59:40 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 8 time(s).
[xlog] 13-01-14 17:59:41 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 9 time(s).
[xlog] 13-01-14 17:59:41 WARN hdfs.DFSClient: Problem renewing lease for DFSClient_-895313119
java.net.ConnectException: Call to xianquanzhang.local/10.2.62.22:8020 failed on connection exception: java.net.ConnectException: 拒绝连接
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy1.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy1.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1359)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1371)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 12 more
[xlog] 13-01-14 17:59:43 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 17:59:44 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 17:59:45 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 17:59:46 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 17:59:47 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 4 time(s).
[xlog] 13-01-14 17:59:48 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 5 time(s).
[xlog] 13-01-14 17:59:48 DEBUG sync.SyncTimer: it start 0 threads to sync data!
[xlog] 13-01-14 17:59:49 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 6 time(s).
[xlog] 13-01-14 17:59:50 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 7 time(s).
[xlog] 13-01-14 17:59:51 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 8 time(s).
[xlog] 13-01-14 17:59:52 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 9 time(s).
[xlog] 13-01-14 17:59:52 WARN hdfs.DFSClient: Problem renewing lease for DFSClient_-895313119
java.net.ConnectException: Call to xianquanzhang.local/10.2.62.22:8020 failed on connection exception: java.net.ConnectException: 拒绝连接
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy1.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy1.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1359)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1371)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 12 more
[xlog] 13-01-14 17:59:54 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 17:59:55 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 17:59:56 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 17:59:57 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 17:59:58 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 4 time(s).
[xlog] 13-01-14 17:59:59 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 5 time(s).
[xlog] 13-01-14 18:00:00 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 6 time(s).
[xlog] 13-01-14 18:00:01 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 7 time(s).
[xlog] 13-01-14 18:00:02 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 8 time(s).
[xlog] 13-01-14 18:00:03 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 9 time(s).
[xlog] 13-01-14 18:00:03 WARN hdfs.DFSClient: Problem renewing lease for DFSClient_-895313119
java.net.ConnectException: Call to xianquanzhang.local/10.2.62.22:8020 failed on connection exception: java.net.ConnectException: 拒绝连接
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy1.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy1.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1359)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1371)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 12 more
[xlog] 13-01-14 18:00:04 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 18:00:05 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 18:00:06 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 18:00:07 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 18:00:08 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 4 time(s).
[xlog] 13-01-14 18:00:09 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 5 time(s).
[xlog] 13-01-14 18:00:10 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 6 time(s).
[xlog] 13-01-14 18:00:11 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 7 time(s).
[xlog] 13-01-14 18:00:12 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 8 time(s).
[xlog] 13-01-14 18:00:13 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 9 time(s).
[xlog] 13-01-14 18:00:13 ERROR impl.HDFSAdapter: fail to close hdfs outputstream
[xlog] 13-01-14 18:00:14 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 18:00:15 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 18:00:16 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 18:00:17 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 18:00:18 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 4 time(s).
[xlog] 13-01-14 18:00:19 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 5 time(s).
[xlog] 13-01-14 18:00:20 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 6 time(s).
[xlog] 13-01-14 18:00:21 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 7 time(s).
[xlog] 13-01-14 18:00:22 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 8 time(s).
[xlog] 13-01-14 18:00:23 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 9 time(s).
[xlog] 13-01-14 18:00:23 WARN hdfs.DFSClient: Problem renewing lease for DFSClient_-895313119
java.net.ConnectException: Call to xianquanzhang.local/10.2.62.22:8020 failed on connection exception: java.net.ConnectException: 拒绝连接
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:1099)
	at org.apache.hadoop.ipc.Client.call(Client.java:1075)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy1.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy1.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1359)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1371)
	at java.lang.Thread.run(Thread.java:662)
Caused by: java.net.ConnectException: 拒绝连接
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:489)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:434)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:560)
	at org.apache.hadoop.ipc.Client$Connection.access$2000(Client.java:184)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1206)
	at org.apache.hadoop.ipc.Client.call(Client.java:1050)
	... 12 more
[xlog] 13-01-14 18:00:24 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 0 time(s).
[xlog] 13-01-14 18:00:25 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 1 time(s).
[xlog] 13-01-14 18:00:26 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 2 time(s).
[xlog] 13-01-14 18:00:27 INFO ipc.Client: Retrying connect to server: xianquanzhang.local/10.2.62.22:8020. Already tried 3 time(s).
[xlog] 13-01-14 18:00:32 WARN hdfs.DFSClient: Problem renewing lease for DFSClient_-895313119
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot renew lease for DFSClient_-895313119. Name node is in safe mode.
The ratio of reported blocks 0.0000 has not reached the threshold 0.9990. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renewLease(FSNamesystem.java:2323)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.renewLease(NameNode.java:825)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

	at org.apache.hadoop.ipc.Client.call(Client.java:1070)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:225)
	at $Proxy1.renewLease(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at $Proxy1.renewLease(Unknown Source)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.renew(DFSClient.java:1359)
	at org.apache.hadoop.hdfs.DFSClient$LeaseChecker.run(DFSClient.java:1371)
	at java.lang.Thread.run(Thread.java:662)
[xlog] 13-01-14 18:00:33 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 0.0000 has not reached the threshold 0.9990. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:33 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:33 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:33 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 0.0022 has not reached the threshold 0.9990. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:34 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:34 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:34 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 0.0022 has not reached the threshold 0.9990. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:34 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:34 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:34 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 0.0022 has not reached the threshold 0.9990. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:35 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:35 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:35 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 0.0022 has not reached the threshold 0.9990. Safe mode will be turned off automatically.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:36 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:36 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:36 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 29 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:36 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:36 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:36 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 29 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:37 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:37 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:37 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:37 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:37 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:37 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 28 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:38 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:38 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:38 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 27 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:39 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:39 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:39 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 26 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:39 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:39 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:39 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 26 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

[xlog] 13-01-14 18:00:40 ERROR impl.HDFSAdapter: fail to recreate HDFSOutputstream,the exception is 
[xlog] 13-01-14 18:00:40 ERROR impl.HDFSAdapter: fail to get HDFSOutputStream,it can't store logdata to hdfs!
[xlog] 13-01-14 18:00:40 ERROR impl.HDFSAdapter: fail to create HDFSOutputstream,then reinitialize hdfs and recreate!the exception is org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create file/user/xianquanzhang/3g/game/test0/2013-01-14-18.x1. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 25 seconds.
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInternal(FSNamesystem.java:1220)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:1188)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.create(NameNode.java:628)
	at sun.reflect.GeneratedMethodAccessor3.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:643)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1388)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1384)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1121)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1382)

